{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"1.1 MNIST Handwritting Images.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"vwydBQEcjSCe"},"source":["### **Handwriting_Images**\n","**Training the neural network to recogonize handwriting images**.\n","How to do handwriting recognition using a Deep Neural Network (DNN) containing three layers -- the input layer (in the shape of the data), the output layer (in the shape of the desired output) and a hidden layer\n","\n","In the course you learned how to do classificaiton using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9. \n","\n","This time train the neural network to recognize the number **4** train[2]\n","\n","Write an MNIST classifier that trains to 95% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n","\n","It should succeed in less than 10 epochs, so it is okay to change epochs= to 10, but nothing larger. When it reaches 95% or greater it should print out the string \"Reached 95% accuracy so cancelling training!\" If you add any additional variables, make sure you use the same names as the ones used in the class\n"]},{"cell_type":"code","metadata":{"id":"DL6-yHCwjSCm"},"source":["# import and load data\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train),(x_test, y_test) = mnist.load_data()\n","\n","# prepare(vectorize)data\n","x_train, x_test = x_train / 255.0, x_test / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aROeq1vnjSC6","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"8c72ab2b-de0d-436c-c9c9-f4eb09b640d9"},"source":["import matplotlib.pyplot as plt\n","plt.imshow(x_train[2])\n","print(y_train[2])\n","print(x_train[2])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4\n","[[0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.2627451  0.90980392 0.15294118 0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.24313725 0.31764706\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.47058824 0.70588235 0.15294118 0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.49411765 0.63921569\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.00784314 0.6        0.82352941 0.15686275 0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.8627451  0.63921569\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.10588235 0.99607843 0.63529412 0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.87058824 0.63921569\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.71764706 0.99607843 0.49019608 0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.18039216 0.96078431 0.63921569\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.77647059 0.99607843 0.21960784 0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.47058824 0.99607843 0.63921569\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.09019608 0.90588235 0.99607843 0.11372549 0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.62352941 0.99607843 0.47058824\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.63921569 0.99607843 0.84705882 0.0627451  0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.62352941 0.99607843 0.2627451\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.05490196 0.3372549  0.69803922\n","  0.97254902 0.99607843 0.35686275 0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.62352941 0.99607843 0.33333333\n","  0.         0.         0.         0.18431373 0.19215686 0.45490196\n","  0.56470588 0.58823529 0.94509804 0.95294118 0.91764706 0.70196078\n","  0.94509804 0.98823529 0.15686275 0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.58823529 0.99215686 0.92941176\n","  0.81176471 0.81176471 0.81176471 0.99215686 0.99607843 0.98039216\n","  0.94117647 0.77647059 0.56078431 0.35686275 0.10980392 0.01960784\n","  0.91372549 0.98039216 0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.46666667 0.69411765\n","  0.69411765 0.69411765 0.69411765 0.69411765 0.38431373 0.21960784\n","  0.         0.         0.         0.         0.         0.4\n","  0.99607843 0.8627451  0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.6627451\n","  0.99607843 0.5372549  0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.6627451\n","  0.99607843 0.22352941 0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.6627451\n","  0.99607843 0.22352941 0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.6627451\n","  1.         0.36862745 0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.6627451\n","  0.99607843 0.37647059 0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.6627451\n","  0.99607843 0.6        0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.6627451\n","  1.         0.6        0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.37647059\n","  0.99607843 0.6        0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANSklEQVR4nO3db4wc9X3H8c/Hx9mOnaD4TH29GAcowQ9opZrqMFX4UypSRFAqgxJZsZTElVAvD2IpSHkApa1ClQclURMatRHSBdw4VQpKlCD8gKQYCxWhRI4P4mIb00KoXewYn1MnsgnGf799cEN0wO3seWd2Z33f90ta3e58d3a+GvnjmZ3f7v4cEQIw981rugEAvUHYgSQIO5AEYQeSIOxAEhf0cmPzvSAWanEvNwmk8qZ+o5NxwjPVKoXd9i2Svi5pQNKDEXFf2fMXarGu8U1VNgmgxLbY2rLW8Wm87QFJ35D0UUlXSlpn+8pOXw9Ad1V5z75a0ssR8UpEnJT0iKQ19bQFoG5Vwr5c0qvTHu8vlr2N7THbE7YnTulEhc0BqKLrV+MjYjwiRiNidFALur05AC1UCfsBSSumPb64WAagD1UJ+3ZJV9i+zPZ8SZ+UtLmetgDUreOht4g4bXuDpH/X1NDbxojYXVtnAGpVaZw9Ih6X9HhNvQDoIj4uCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKVZnEF+tlvPnFNy9qXv/JA6bpfWvuZ0npM7OqopyZVCrvtvZKOSToj6XREjNbRFID61XFk/9OI+GUNrwOgi3jPDiRRNewh6Qnbz9oem+kJtsdsT9ieOKUTFTcHoFNVT+Ovi4gDtpdJ2mL7xYh4evoTImJc0rgkXeihqLg9AB2qdGSPiAPF30lJj0paXUdTAOrXcdhtL7b9vrfuS7pZ0vk3HgEkUeU0fljSo7bfep1/i4gf1dJVFxxfU37ScXzpQGl9aONP6mwHPTA52vpY9qW9f97DTvpDx2GPiFck/WGNvQDoIobegCQIO5AEYQeSIOxAEoQdSCLNV1x/cUP5/2uLLv91+QtsrLEZ1GNe+XBpfPB4y9pNy14sXXerP9xRS/2MIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJJFmnP3vPva90vqX99zco05Ql4HLLymtv/gnrT8cseqnnypd9wPbd3bUUz/jyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSaQZZx/06aZbQM0uePCNjtc9/vMLa+zk/MCRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSmDPj7GevW1Vav37hMz3qBL1y6eL/63jdFU+eqbGT80PbI7vtjbYnbe+atmzI9hbbLxV/l3S3TQBVzeY0/luSbnnHsrslbY2IKyRtLR4D6GNtwx4RT0s68o7FayRtKu5vknRbzX0BqFmn79mHI+Jgcf81ScOtnmh7TNKYJC3Uog43B6CqylfjIyIkRUl9PCJGI2J0UAuqbg5AhzoN+yHbI5JU/J2sryUA3dBp2DdLWl/cXy/psXraAdAtbd+z235Y0o2SLrK9X9IXJd0n6bu275C0T9LabjY5G/s+9p7S+rIBrhecby649IOl9U8Mbe74td/zP78qrc/FUfi2YY+IdS1KN9XcC4Au4uOyQBKEHUiCsANJEHYgCcIOJDFnvuJ6wYeOVVr/zRffX1MnqMur/7i4tH7tgrOl9YeOXty6+OujnbR0XuPIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJzJlx9qqWTZSP2WJmAxctLa0f+vjKlrWhtftL1/2PlQ+12frC0uoD32j904jLDv24zWvPPRzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtkLx4fK/98r/2Z1NWevv6q0HgMurb/6kdYz7Zz8wKnSdefNL//R5Ceu/6fS+mB5a3rtTOve/vaV20vXPXK2/LMPi+aV9z68rfVvHLScwmgO48gOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0nMmXH2E28OltbPthlZ/Zd77i+tb96w6px7mq27lj5YWp+n8sHs43GyZe0XZ8rHov/58I2l9Y88eWdp/f0/m19aH3niUMua95V/n/3wnvJpuIcHyj9DENt3ltazaXtkt73R9qTtXdOW3Wv7gO0dxe3W7rYJoKrZnMZ/S9ItMyy/PyJWFbfH620LQN3ahj0inpZ0pAe9AOiiKhfoNth+vjjNX9LqSbbHbE/YnjilExU2B6CKTsP+gKTLJa2SdFDSV1s9MSLGI2I0IkYH1fpLEQC6q6OwR8ShiDgTEWclfVPS6nrbAlC3jsJue2Taw9sl7Wr1XAD9oe04u+2HJd0o6SLb+yV9UdKNtldp6mvBeyV9tos9zsqHPvWz0vrv//2G0vqKqw/U2c45eWqy9W+rS9LhH5bMMy5p6e7W483zf7S9zdbLx6pXaqLN+uXKRvkP3PXh0nWvXvCT0vojry/voKO82oY9ItbNsLjdr/cD6DN8XBZIgrADSRB2IAnCDiRB2IEk5sxXXNu57K/Kh3H62Yj+t+kWumLRDYcrrf83T328tL5SP630+nMNR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSCLNODvmnkseyzjxcuc4sgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASfJ8dfWvA5ceiX60cLK3/7g/r7Ob81/bIbnuF7adsv2B7t+3PF8uHbG+x/VLxd0n32wXQqdmcxp+W9IWIuFLSH0v6nO0rJd0taWtEXCFpa/EYQJ9qG/aIOBgRzxX3j0naI2m5pDWSNhVP2yTptm41CaC6c3rPbvtSSVdJ2iZpOCIOFqXXJA23WGdM0pgkLdSiTvsEUNGsr8bbfq+k70u6MyKOTq9FREia8df/ImI8IkYjYnRQCyo1C6Bzswq77UFNBf07EfGDYvEh2yNFfUTSZHdaBFCH2VyNt6SHJO2JiK9NK22WtL64v17SY/W3h8zOxNnSm+ap/Ia3mc179mslfVrSTts7imX3SLpP0ndt3yFpn6S13WkRQB3ahj0inpHkFuWb6m0HQLdwsgMkQdiBJAg7kARhB5Ig7EASfMUV5603rn6j6RbOKxzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtnRt9r9lDTODXsTSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnB2NOfHk75TWz6w626NOcuDIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJOCLKn2CvkPRtScOSQtJ4RHzd9r2S/lLS4eKp90TE42WvdaGH4hoz8SvQLdtiq47GkRlnXZ7Nh2pOS/pCRDxn+32SnrW9pajdHxH/UFejALpnNvOzH5R0sLh/zPYeScu73RiAep3Te3bbl0q6StK2YtEG28/b3mh7SYt1xmxP2J44pROVmgXQuVmH3fZ7JX1f0p0RcVTSA5Iul7RKU0f+r860XkSMR8RoRIwOakENLQPoxKzCbntQU0H/TkT8QJIi4lBEnImIs5K+KWl199oEUFXbsNu2pIck7YmIr01bPjLtabdL2lV/ewDqMpur8ddK+rSknbZ3FMvukbTO9ipNDcftlfTZrnQIoBazuRr/jKSZxu1Kx9QB9Bc+QQckQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii7U9J17ox+7CkfdMWXSTplz1r4Nz0a2/92pdEb52qs7dLImLGubB7GvZ3bdyeiIjRxhoo0a+99WtfEr11qle9cRoPJEHYgSSaDvt4w9sv06+99WtfEr11qie9NfqeHUDvNH1kB9AjhB1IopGw277F9n/Zftn23U300IrtvbZ32t5he6LhXjbanrS9a9qyIdtbbL9U/J1xjr2GervX9oFi3+2wfWtDva2w/ZTtF2zvtv35Ynmj+66kr57st56/Z7c9IOm/Jf2ZpP2StktaFxEv9LSRFmzvlTQaEY1/AMP2DZJel/TtiPiDYtlXJB2JiPuK/yiXRMRdfdLbvZJeb3oa72K2opHp04xLuk3SX6jBfVfS11r1YL81cWRfLenliHglIk5KekTSmgb66HsR8bSkI+9YvEbSpuL+Jk39Y+m5Fr31hYg4GBHPFfePSXprmvFG911JXz3RRNiXS3p12uP96q/53kPSE7aftT3WdDMzGI6Ig8X91yQNN9nMDNpO491L75hmvG/2XSfTn1fFBbp3uy4i/kjSRyV9rjhd7Usx9R6sn8ZOZzWNd6/MMM34bzW57zqd/ryqJsJ+QNKKaY8vLpb1hYg4UPydlPSo+m8q6kNvzaBb/J1suJ/f6qdpvGeaZlx9sO+anP68ibBvl3SF7ctsz5f0SUmbG+jjXWwvLi6cyPZiSTer/6ai3ixpfXF/vaTHGuzlbfplGu9W04yr4X3X+PTnEdHzm6RbNXVF/ueS/rqJHlr09XuS/rO47W66N0kPa+q07pSmrm3cIWmppK2SXpL0pKShPurtXyXtlPS8poI10lBv12nqFP15STuK261N77uSvnqy3/i4LJAEF+iAJAg7kARhB5Ig7EAShB1IgrADSRB2IIn/Bziw80r6zfkYAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Inzgx3EWjSDG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6bea6ff9-e1ae-4ed8-c42a-df76a5039e5b"},"source":["# build(layers) and compile neural network\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28)),\n","  tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train, epochs=5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 12s 7ms/step - loss: 0.1881 - accuracy: 0.9431\n","Epoch 2/5\n","1875/1875 [==============================] - 13s 7ms/step - loss: 0.0737 - accuracy: 0.9769\n","Epoch 3/5\n","1875/1875 [==============================] - 13s 7ms/step - loss: 0.0474 - accuracy: 0.9858\n","Epoch 4/5\n","1875/1875 [==============================] - 13s 7ms/step - loss: 0.0349 - accuracy: 0.9889\n","Epoch 5/5\n","1875/1875 [==============================] - 12s 7ms/step - loss: 0.0271 - accuracy: 0.9909\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd25bfd75f8>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"e12NGTr4lMrA"},"source":["### **Summary**\n","We had an accuracy of 0.99, this was a very good result of the training model"]}]}